{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Installation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%pip install 'jax[cpu]'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Jax 를 Numpy처럼 사용하기"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "사용자는 대부분 jax.numpy를 통해, 마치 numpy를 사용하듯 jax를 사용하게 됩니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import jax.numpy as jnp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.        1.05      2.1       3.1499999 4.2      ]\n"
     ]
    }
   ],
   "source": [
    "def selu(x, alpha=1.67, lmbda=1.05):\n",
    "  return lmbda * jnp.where(x > 0, x, alpha * jnp.exp(x) - alpha)\n",
    "\n",
    "x = jnp.arange(5.0)\n",
    "print(selu(x))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## `jax.jit()` 사용하기"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`jax.jit()` 를 사용하면 XLA를 사용하여 함수를 컴파일 할 수 있습니다. 이를 통해 속도를 높일 수 있습니다."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "jax 연산은 성능을 위해서 파이썬과 비동기적으로 돌아갑니다. 이러한 속성 때문에 jax를 사용하는 함수의 정확한 시간 측정을 위해서는 `block_until_ready()`를 사용해야 합니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.63 ms ± 74.3 µs per loop (mean ± std. dev. of 7 runs, 1,000 loops each)\n"
     ]
    }
   ],
   "source": [
    "from jax import random\n",
    "key = random.key(0)\n",
    "x = random.normal(key, (1000000, )) # jax에서는 랜덤한 수를 생성할 때마다 seed를 넣어줍니다.\n",
    "%timeit selu(x).block_until_ready()  # runs on the CPU"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "이번에는 `jax.jit()`를 사용하여 `selu` 함수를 실행해 보겠습니다:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "632 µs ± 17.3 µs per loop (mean ± std. dev. of 7 runs, 1,000 loops each)\n"
     ]
    }
   ],
   "source": [
    "from jax import jit\n",
    "\n",
    "selu_jit = jit(selu)\n",
    "_ = selu_jit(x) # 첫 실행은 jit을 컴파일하는 단계이므로, 최소 한번의 실행 이후 속도의 이점을 볼 수 있습니다. warm-up 단계로 생각해도 좋습니다.\n",
    "%timeit selu_jit(x).block_until_ready()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## `jax.grad()`를 사용하여 미분하기"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`jax.grad()`를 사용하면 함수의 도함수를 구할 수 있습니다. `jax.grad()` 는 [automatic differentiation](https://velog.io/@gypsi12/Auto-Differentiation자동미분-이란), 즉, 자동미분 방법을 사용합니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "x^2 = 16.0\n",
      "2x = 8.0\n",
      "2 = 2.0\n"
     ]
    }
   ],
   "source": [
    "from jax import grad\n",
    "\n",
    "def squared(x):\n",
    "    return x**2\n",
    "\n",
    "print(f\"x^2 = {squared(4.0)}\")               # y = x^2\n",
    "\n",
    "grad_fn = grad(squared)\n",
    "print(f\"2x = {grad_fn(4.0)}\")               # y = 2x\n",
    "\n",
    "grad_grad_fn = grad(grad_fn)\n",
    "print(f\"2 = {grad_grad_fn(4.0)}\")          # y =2\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## `jax.vmap()`으로 백터화하기"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`jax.vmap()`을 이용하여 동일한 연산을 병렬로 수행할 수 있습니다.\n",
    "다만 `jax.vmap()`은 컴퓨터 단에서 멀티프로세싱을 한다는 말은 아닙니다. 스칼라끼리의 곱셈을 행렬연산으로 바꾸면 한 번의 계산으로 여러 곱셈을 효율적이고 빠르게 할 수 있듯이, 내부적으로 여러개의 연산을 한번의 계산으로 바꾸어 처리하는 방법입니다.\n",
    "멀티프로세싱을 사용하는 방법은 `jax.pmap()`을 통해 가능합니다."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "간단한 예제를 살펴보겠습니다. 해당 문제는 `jax.vmap()`를 굳이 사용하지 않아도 될 만큼 간단한 문제이지만, `jax.vmap()`의 작동 방식을 보여드리기 위해 사용하였습니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "key1, key2 = random.split(key)\n",
    "mat = random.normal(key1, (150, 100))\n",
    "batched_x = random.normal(key2, (10, 100))\n",
    "\n",
    "def apply_matrix(x):\n",
    "  return jnp.dot(mat, x)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`mat` 와 `batched_x` 를 행렬곱하고 싶을 때, 행렬곱을 시행할 수 있는 가장 멍청한 방법은 다음일 것입니다:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Naively batched\n",
      "456 µs ± 5.22 µs per loop (mean ± std. dev. of 7 runs, 1,000 loops each)\n"
     ]
    }
   ],
   "source": [
    "def naively_batched_apply_matrix(v_batched):\n",
    "  return jnp.stack([apply_matrix(v.T) for v in v_batched])\n",
    "\n",
    "print('Naively batched')\n",
    "%timeit naively_batched_apply_matrix(batched_x).block_until_ready()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "하지만 저희는 더 좋은 방법을 알고 있습니다. 한 행 한 행 따로 연산할 필요 없이, `batched_x`를 transpose(전치)하여 `mat`와 행렬곱을 하면 훨씬 효율적으로 같은 결과를 얻을 수 있습니다. `jnp.dot()` 함수를 통해 행렬곱을 시행할 수 있습니다:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Manually batched\n",
      "16.4 µs ± 73.5 ns per loop (mean ± std. dev. of 7 runs, 100,000 loops each)\n"
     ]
    }
   ],
   "source": [
    "@jit\n",
    "def batched_apply_matrix(batched_x):\n",
    "  return jnp.dot(batched_x, mat.T)\n",
    "\n",
    "print('Manually batched')\n",
    "%timeit batched_apply_matrix(batched_x).block_until_ready()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`jax.vmap()`은 사용자가 직접 배치 처리를 설계하지 않아도 되도록 도와줍니다:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Auto-vectorized with vmap\n",
      "22.8 µs ± 126 ns per loop (mean ± std. dev. of 7 runs, 10,000 loops each)\n"
     ]
    }
   ],
   "source": [
    "from jax import vmap\n",
    "\n",
    "@jit\n",
    "def vmap_batched_apply_matrix(batched_x):\n",
    "  return vmap(apply_matrix)(batched_x)\n",
    "\n",
    "print('Auto-vectorized with vmap')\n",
    "%timeit vmap_batched_apply_matrix(batched_x).block_until_ready()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "지금 예제로 다루고 있는 문제는 `jnp.dot()` 만을 통해서 충분히 아름답게 해결할 수 있습니다. 하지만 내부 로직이 복잡해 질 수록 다양한 변수에 대하여 계산 오류가 생기지 않도록 신경써주어야 하고, 이는 코드를 난잡하게 만듭니다. 즉, `jnp.vmap()` 은 함수가 복잡해 질 수록 빛을 발합니다."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`jax.vmap()` 위에 `jax.jit()` 를 씌우던, `jax.jit()` 위에 `jax.vmap()` 를 씌우던 전혀 무관합니다."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "jax",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
